{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILg5nyL7nhV1"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "multinews = load_dataset(\"multi_news\")\n",
        "\n",
        "multinews"
      ],
      "metadata": {
        "id": "kA9l9GhOnpUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Then, convert each dataset in the DatasetDict to a pandas DataFrame\n",
        "train_df = pd.DataFrame(multinews['train'])\n",
        "validation_df = pd.DataFrame(multinews['validation'])\n",
        "test_df = pd.DataFrame(multinews['test'])\n",
        "\n",
        "# Concatenate the DataFrames to create a single DataFrame\n",
        "multinews_df = pd.concat([train_df, validation_df, test_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "BnSQCLDynrrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA UNDERSTANDING"
      ],
      "metadata": {
        "id": "nCtQnbkqntaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview of the dataset structure\n",
        "print(multinews_df.info())\n",
        "print(multinews_df.head())\n",
        "\n",
        "# Dataset size\n",
        "num_documents = len(multinews_df)\n",
        "print(f\"Number of documents: {num_documents}\")"
      ],
      "metadata": {
        "id": "IfHNjfImnvi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA QUALITY"
      ],
      "metadata": {
        "id": "F4h3EO60nzA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values check\n",
        "missing_values = multinews_df.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)\n",
        "\n",
        "# Data consistency check: Ensure every document has a summary\n",
        "consistent_pairs = multinews_df.dropna(subset=['document', 'summary'])\n",
        "print(f\"Consistent document-summary pairs: {len(consistent_pairs)}\")"
      ],
      "metadata": {
        "id": "U9w0W1u0nxYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Duplicate documents/summaries\n",
        "duplicates = multinews_df.duplicated(subset=['document', 'summary'])\n",
        "print(f\"Number of duplicate pairs: {duplicates.sum()}\")\n",
        "\n",
        "# Remove duplicates\n",
        "df = multinews_df.drop_duplicates(subset=['document', 'summary'])"
      ],
      "metadata": {
        "id": "xrSl9BC6tNp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANALISI LUNGHEZZE"
      ],
      "metadata": {
        "id": "DIYushnooHKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Document and summary length analysis\n",
        "df['doc_length_sentences'] = df['document'].apply(lambda x: len(sent_tokenize(x)))\n",
        "df['doc_length_words'] = df['document'].apply(lambda x: len(word_tokenize(x)))\n",
        "\n",
        "df['summary_length_sentences'] = df['summary'].apply(lambda x: len(sent_tokenize(x)))\n",
        "df['summary_length_words'] = df['summary'].apply(lambda x: len(word_tokenize(x)))"
      ],
      "metadata": {
        "id": "HdMblJ8XoCk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_doc_length = multinews_df['doc_length_words'].max()\n",
        "print(\"Maximum document length:\", max_doc_length)\n",
        "\n",
        "min_doc_length = multinews_df['doc_length_words'].min()\n",
        "print(\"Minimum document length:\", min_doc_length)\n",
        "\n",
        "max_summary_length = multinews_df['summary_length_words'].max()\n",
        "print(\"Maximum summary length:\", max_summary_length)\n",
        "\n",
        "min_summary_length = multinews_df['summary_length_words'].min()\n",
        "print(\"Minimum summary length:\", min_summary_length)\n",
        "\n",
        "# Calculate median lengths\n",
        "median_doc_length = multinews_df['doc_length_words'].median()\n",
        "median_summary_length = multinews_df['summary_length_words'].median()\n",
        "\n",
        "print(f\"Median document length (in words): {median_doc_length}\")\n",
        "print(f\"Median summary length (in words): {median_summary_length}\")"
      ],
      "metadata": {
        "id": "XL-flryQn2u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of lengths\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the histogram for Document Length\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(multinews_df['doc_length_words'], bins=2000, alpha=0.7, color=(.90, .4, .4), ec='black')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlim([0, 18000])  # Set x-axis range\n",
        "plt.ylim([0, 7000])  # Set y-axis range\n",
        "plt.title('Distribution of Document Lengths')\n",
        "plt.show()\n",
        "\n",
        "# Plot the histogram for Summary Length\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(multinews_df['summary_length_words'], bins=50, alpha=0.7, color='lightblue', ec='black')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlim([0, 1200])  # Set x-axis range\n",
        "plt.ylim([0, 7000])  # Set y-axis range\n",
        "plt.title('Distribution of Summary Lengths')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xS0pswhsoFAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANALISI NUMERO TESTI PER DOCUMENTO"
      ],
      "metadata": {
        "id": "Osm6QbkmoKGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to count sources\n",
        "def count_sources(document):\n",
        "    return document.count('|||||') + 1\n",
        "\n",
        "# Apply function to each document in the DataFrame\n",
        "multinews_df['num_sources'] = multinews_df['document'].apply(count_sources)\n",
        "\n",
        "# Count number of documents for each number of sources\n",
        "source_counts = multinews_df['num_sources'].value_counts().sort_index()\n"
      ],
      "metadata": {
        "id": "U6EQ7p3_oQEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the minimum number of sources\n",
        "min_sources = multinews_df['num_sources'].min()\n",
        "print(\"Minimum number of sources:\", min_sources)\n",
        "\n",
        "# Determine the maximum number of sources\n",
        "max_sources = multinews_df['num_sources'].max()\n",
        "print(\"Maximum number of sources:\", max_sources)\n",
        "\n",
        "# Determine the median number of sources\n",
        "median_sources = multinews_df['num_sources'].median()\n",
        "print(\"Median number of sources:\", median_sources)"
      ],
      "metadata": {
        "id": "EpEcpl_uoS_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(source_counts.index, source_counts.values, color=(.90, .4, .4), ec='black')\n",
        "plt.xlabel('Number of Sources')\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.title('Number of Sources in Documents')\n",
        "plt.xticks(source_counts.index)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7hjohU_0oSUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}